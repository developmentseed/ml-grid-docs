---
title: Machine learning
date: 2012-08-23
layout: post.html
---

With the imagery downloaded, the next step was to autonomously investigate these images for HV towers. For each raster image, we generated a probability score on the interval [0, 1] that a HV tower was present. We accomplished this using a convolutional neural network (CNN) which took raster images as input, and a single probability as output. Specifically, we used the XCeption neural network (Chollet, 2016), as it has shown excellent scores on the ImageNet benchmark test set and has relatively few parameters relative to comparable CNNs (e.g., VGG and Inception). The latter fact implies faster training and prediction runtimes simply because there are fewer point computations per image.

The XCeption model was trained using three small datasets -- one from each of the three target countries. The data team manually validated all tiles in these three countries. This involved checking every inch of ground so that we were confident our training dataset did not miss any towers, which would hurt our ML model performance during the inference stage (i.e., predicting on a country-wide image set). The training procedure leveraged transfer learning: the XCeption model was initialized (in Keras) using weights from ImageNet training. We then re-trained only the top layer for 2-5 epochs so that it would output the probability of 2 classes (HV tower present or absent), and finally opened up training to all layers to fine tune the entire model.

In training, we used the binary cross-entropy loss function and generally trained over 15-30 epochs of the total training dataset. We also used Keras’s utility functions including early stopping, and automatically reduced learning rate when validation loss hit a plateau. The dataset was augmented by using Keras’s image preprocessing functions to randomly flip, rotate, and scale original images during the training procedure. Results were visualized with tensorboard to monitor model progress. For hyperparameters, we used the [Hyperopt library](https://github.com/hyperopt/hyperopt) to intelligently iterate over different hyperparameter combinations. The full list of hyperparameters is available in `config.py`, but generally this included options like the optimizer, learning rate, initialization strategy, etc. We selected an optimal model based on the highest accuracy score achieved on the held-out testing data across all Hyperopt iterations.

We carried out all country-wide predictions in the inference stage on AWS EC2 instances optimized for GPU compute. Specifically, we used the `p2.xlarge` and `p2.8xlarge` instance types and ran these as Spot Instances (as opposed to On-Demand) to reduce AWS costs. We typically ran 2-3 instances at a time to increase throughput. On each instance, we processed large batches of images one at a time. Each country was generally divided up into about 7-10 batches (according to the X-indices of tiles) as it was not feasible to transfer an entire country’s worth of tiles from S3 to the EC2 instance. While computing probability scores, the prediction script periodically uploaded tile prediction scores (as a JSON file) to S3 while processing (around every 5,000 images). This ensured that the prediction was fault tolerant -- all scores were not lost when the instance shut down unexpectedly.
